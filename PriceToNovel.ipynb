{
 "cells": [
  {
   "cell_type": "code",
   "id": "e450647c-4955-4671-a355-c72ffea7451d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T22:52:21.966213Z",
     "start_time": "2024-08-20T22:52:21.014943Z"
    }
   },
   "source": [
    "import pandas as pd  # Import the pandas library for data manipulation and analysis\n",
    "import matplotlib.pyplot as plt  # Import the matplotlib library for plotting\n",
    "\n",
    "# Read the CSV file containing EUR/USD exchange rate data, using tab as the delimiter\n",
    "df = pd.read_csv(\"dataset/EURUSDH4.csv\", delimiter=\"\\t\")\n",
    "\n",
    "# Extract the closing prices from the DataFrame\n",
    "closing = df[\"<CLOSE>\"]\n",
    "\n",
    "# Calculate the difference between consecutive closing prices and drop any missing values\n",
    "closing_delta = closing.diff().dropna()\n",
    "\n",
    "# Standardize the closing delta values to have a mean of 0 and a standard deviation of 1\n",
    "standardized_closing_delta = (closing_delta - closing_delta.mean()) / closing_delta.std()\n",
    "\n",
    "# Replace extremes with the minimum and maximum possible values\n",
    "standardized_closing_delta_clipped = standardized_closing_delta.clip(lower=-3, upper=3)\n",
    "\n",
    "# Plot the histogram of the clipped standardized closing delta values\n",
    "plt.figure(figsize=(10, 5))  # Set the figure size for the plot\n",
    "plt.hist(standardized_closing_delta_clipped, bins=30, color='salmon', edgecolor='black', alpha=0.7)  # Create a histogram\n",
    "plt.title('Histogram of Clipped Standardized Closing Delta')  # Set the title of the plot\n",
    "plt.xlabel('Standardized Closing Delta')  # Label for the x-axis\n",
    "plt.ylabel('Frequency')  # Label for the y-axis\n",
    "plt.grid(axis='y')  # Add a grid to the y-axis\n",
    "plt.show()  # Display the plot"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "f585d98d-c10b-4cb1-837f-76e2b11c8b63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T22:52:21.975007Z",
     "start_time": "2024-08-20T22:52:21.968136Z"
    }
   },
   "source": [
    "# Convert the standardized closing delta values to bins from 0 to 9\n",
    "# First, we scale the values to the range [0, 9]\n",
    "bins = 9\n",
    "scaled_closing_delta = ((standardized_closing_delta_clipped + 3) / 6) * bins  # Scale to [0, 9]\n",
    "scaled_closing_delta_binned = scaled_closing_delta.round().clip(0, bins)  # Round and clip to ensure values are between 0 and 9"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "5059ea12-8372-418d-b060-dc2232815184",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T22:52:22.105655Z",
     "start_time": "2024-08-20T22:52:21.976202Z"
    }
   },
   "source": [
    "# Plot the histogram of the binned standardized closing delta values\n",
    "plt.figure(figsize=(10, 5))  # Set the figure size for the plot\n",
    "plt.hist(scaled_closing_delta_binned, bins=bins + 1, color='lightgreen', edgecolor='black', alpha=0.7)  # Create a histogram\n",
    "plt.title('Histogram of Binned Standardized Closing Delta (0 to 9)')  # Set the title of the plot\n",
    "plt.xlabel('Binned Standardized Closing Delta')  # Label for the x-axis\n",
    "plt.ylabel('Frequency')  # Label for the y-axis\n",
    "plt.xticks(range(0, bins + 1))  # Set x-ticks to show bins from 0 to 9\n",
    "plt.grid(axis='y')  # Add a grid to the y-axis\n",
    "plt.show()  # Display the plot"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Counting unique words suggested by my Friend",
   "id": "d077b79350711575"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T22:53:08.363393Z",
     "start_time": "2024-08-20T22:52:22.107942Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "# if max_word_size range is from 8 to 10 produced ~100 000 words and ~200 000 sentences\n",
    "# in range 3 to 5 number of words is ~5000\n",
    "word_size_low_range = 3\n",
    "word_size_high_range = 5\n",
    "\n",
    "# Track unique words using a set\n",
    "unique_words = set()\n",
    "num_rows = scaled_closing_delta_binned.shape[0]\n",
    "\n",
    "# Open both files in write mode using context managers\n",
    "with (open(\"dataset/Present_large.txt\", \"w\") as file_present, \n",
    "      open(\"dataset/Future_large.txt\", \"w\") as file_future):\n",
    "\n",
    "    # Iterate multiple times to generate data\n",
    "    for repeat in range(0, 5):\n",
    "        # Define minimum and maximum lengths for sentences\n",
    "        min_sentences_len = np.random.randint(18, 20)\n",
    "        max_sentences_len = np.random.randint(40, 50)\n",
    "        \n",
    "        # Define the maximum size for individual words\n",
    "        max_word_size = np.random.randint(word_size_low_range, word_size_high_range)  # Example maximum word size\n",
    "        \n",
    "        # Loop through indices starting from min_sentences_len to the total length\n",
    "        for idx in range(0, num_rows - max_sentences_len):\n",
    "            # Generate a random integer for the total length of two sentences\n",
    "            two_sentence_length = np.random.randint(min_sentences_len, max_sentences_len)\n",
    "            \n",
    "            # Calculate 40% to 60% of the total sentence length for the present sentence\n",
    "            present_sentence_length = int(np.random.uniform(0.4, 0.6) * two_sentence_length)\n",
    "        \n",
    "            # Split the present_sentence_length into random length words\n",
    "            present_word_sizes = []\n",
    "            remaining_length = present_sentence_length\n",
    "            \n",
    "            # Continue generating words until the remaining length is exhausted\n",
    "            while remaining_length > 0:\n",
    "                word_size = np.random.randint(1, min(remaining_length, max_word_size) + 1)\n",
    "                present_word_sizes.append(word_size)\n",
    "                remaining_length -= word_size\n",
    "            \n",
    "            # Calculate the remaining length for the future sentence\n",
    "            future_sentence_len = two_sentence_length - present_sentence_length\n",
    "            \n",
    "            # Split the future_sentence_len into random length words\n",
    "            future_word_sizes = []\n",
    "            remaining_length = future_sentence_len\n",
    "            \n",
    "            # Continue generating words until the remaining length is exhausted\n",
    "            while remaining_length > 0:\n",
    "                word_size = np.random.randint(1, min(remaining_length, max_word_size) + 1)\n",
    "                future_word_sizes.append(word_size)\n",
    "                remaining_length -= word_size\n",
    "        \n",
    "            # Process the sentences\n",
    "            present_sentence = scaled_closing_delta_binned.iloc[idx:idx+present_sentence_length]\n",
    "            future_sentence = scaled_closing_delta_binned.iloc[idx+present_sentence_length:idx+two_sentence_length]\n",
    "\n",
    "            # Words for Present Sentence\n",
    "            present_sentence_str = ''\n",
    "            k = 0\n",
    "            for p_idx in present_word_sizes:\n",
    "                word = ''.join(str(int(n)) for n in present_sentence.iloc[k:k+p_idx])\n",
    "                present_sentence_str += (' ' + word) if present_sentence_str else word\n",
    "                k += p_idx\n",
    "                unique_words.add(word)  # Add the word to the set of unique words\n",
    "                \n",
    "            file_present.write(present_sentence_str + \"\\n\") \n",
    "            \n",
    "            # Words for Future Sentence    \n",
    "            future_sentence_str = ''\n",
    "            k = 0\n",
    "            for p_idx in future_word_sizes:\n",
    "                word = ''.join(str(int(n)) for n in future_sentence.iloc[k:k+p_idx])\n",
    "                future_sentence_str += (' ' + word) if future_sentence_str else word\n",
    "                k += p_idx\n",
    "                unique_words.add(word)  # Add the word to the set of unique words\n",
    "            \n",
    "            file_future.write(future_sentence_str + \"\\n\") \n",
    "\n",
    "        print(f\"Repeat {repeat} complete.\")\n",
    "\n",
    "print(\"Finished writing to Present.txt and Future.txt.\") \n",
    "print(f\"Total unique words: {unique_words.__len__()}\")"
   ],
   "id": "3f9b3d72-d5ef-48f1-9bf8-62be67ae5c90",
   "execution_count": 4,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-20T22:53:08.366345Z",
     "start_time": "2024-08-20T22:53:08.364461Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "26b74fa5c79402b7",
   "execution_count": 4,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
