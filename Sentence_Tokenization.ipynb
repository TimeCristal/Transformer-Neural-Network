{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "g6lvIJaCEjPY",
    "ExecuteTime": {
     "end_time": "2024-08-13T22:54:08.584980Z",
     "start_time": "2024-08-13T22:54:08.580264Z"
    }
   },
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from transformer import Transformer, PositionalEncoding, get_device\n",
    "sentence_num = 0"
   ],
   "execution_count": 175,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# english_file = 'drive/MyDrive/translation_en_kn/train.en'\n",
    "english_file = '/Users/krasimirtrifonov/Documents/GitHub/Transformer-Neural-Network/dataset/Present.txt'\n",
    "# kannada_file = 'drive/MyDrive/translation_en_kn/train.kn'\n",
    "kannada_file = '/Users/krasimirtrifonov/Documents/GitHub/Transformer-Neural-Network/dataset/Future.txt'\n",
    "\n",
    "START_TOKEN = '<START>'\n",
    "PADDING_TOKEN = '<PADDING>'\n",
    "END_TOKEN = '<END>'\n",
    "\n",
    "kannada_vocabulary = [START_TOKEN, ' ', '0', '1','2','3','4','5','6','7','8','9', PADDING_TOKEN, END_TOKEN]\n",
    "\n",
    "english_vocabulary = kannada_vocabulary"
   ],
   "metadata": {
    "id": "c9Sf9_Y-E564",
    "ExecuteTime": {
     "end_time": "2024-08-13T22:54:08.618515Z",
     "start_time": "2024-08-13T22:54:08.615789Z"
    }
   },
   "execution_count": 176,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "text = '012'\n",
    "list(text)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b0PcdLN_lmUT",
    "outputId": "d07d14cd-a966-4f1d-e935-756f499f5163",
    "ExecuteTime": {
     "end_time": "2024-08-13T22:54:08.641791Z",
     "start_time": "2024-08-13T22:54:08.638141Z"
    }
   },
   "execution_count": 177,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "'0' + '1'",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 37
    },
    "id": "JuvbnQVOoHr_",
    "outputId": "e64cbda7-ee9c-47eb-ccd9-ead8d44ee5fe",
    "ExecuteTime": {
     "end_time": "2024-08-13T22:54:08.672678Z",
     "start_time": "2024-08-13T22:54:08.667060Z"
    }
   },
   "execution_count": 178,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "index_to_kannada = {k:v for k,v in enumerate(kannada_vocabulary)}\n",
    "kannada_to_index = {v:k for k,v in enumerate(kannada_vocabulary)}\n",
    "index_to_english = {k:v for k,v in enumerate(english_vocabulary)}\n",
    "english_to_index = {v:k for k,v in enumerate(english_vocabulary)}"
   ],
   "metadata": {
    "id": "L1WoSOS5FH2U",
    "ExecuteTime": {
     "end_time": "2024-08-13T22:54:08.710002Z",
     "start_time": "2024-08-13T22:54:08.706965Z"
    }
   },
   "execution_count": 179,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "with open(english_file, 'r') as file:\n",
    "    english_sentences = file.readlines()\n",
    "with open(kannada_file, 'r') as file:\n",
    "    kannada_sentences = file.readlines()\n",
    "\n",
    "# Limit Number of sentences\n",
    "TOTAL_SENTENCES = 100000\n",
    "english_sentences = english_sentences[:TOTAL_SENTENCES]\n",
    "kannada_sentences = kannada_sentences[:TOTAL_SENTENCES]\n",
    "english_sentences = [sentence.rstrip('\\n') for sentence in english_sentences]\n",
    "kannada_sentences = [sentence.rstrip('\\n') for sentence in kannada_sentences]"
   ],
   "metadata": {
    "id": "vRetf6-9FJ8p",
    "ExecuteTime": {
     "end_time": "2024-08-13T22:54:08.737081Z",
     "start_time": "2024-08-13T22:54:08.732311Z"
    }
   },
   "execution_count": 180,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "english_sentences[:10]"
   ],
   "metadata": {
    "id": "dmrrz9ZZFRi1",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "99e1cbfc-9c4a-4f45-f08e-364de5d28534",
    "ExecuteTime": {
     "end_time": "2024-08-13T22:54:08.769773Z",
     "start_time": "2024-08-13T22:54:08.766582Z"
    }
   },
   "execution_count": 181,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "kannada_sentences[:10]"
   ],
   "metadata": {
    "id": "F9jdseUqFSEb",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "79d14c06-5658-4c57-b500-86a6f7625ff5",
    "ExecuteTime": {
     "end_time": "2024-08-13T22:54:08.791891Z",
     "start_time": "2024-08-13T22:54:08.788353Z"
    }
   },
   "execution_count": 182,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "max(len(x) for x in kannada_sentences), max(len(x) for x in english_sentences),"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SBQmCJuqza3a",
    "outputId": "d4bb6033-e1b0-49f3-8137-ee5176f9e825",
    "ExecuteTime": {
     "end_time": "2024-08-13T22:54:08.817500Z",
     "start_time": "2024-08-13T22:54:08.813282Z"
    }
   },
   "execution_count": 183,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "PERCENTILE = 97\n",
    "print( f\"{PERCENTILE}th percentile length Kannada: {np.percentile([len(x) for x in kannada_sentences], PERCENTILE)}\" )\n",
    "print( f\"{PERCENTILE}th percentile length English: {np.percentile([len(x) for x in english_sentences], PERCENTILE)}\" )"
   ],
   "metadata": {
    "id": "-8m1B0P3FUFX",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "f28b333d-bfc9-4d16-dd63-284ff7897d38",
    "ExecuteTime": {
     "end_time": "2024-08-13T22:54:08.856409Z",
     "start_time": "2024-08-13T22:54:08.851289Z"
    }
   },
   "execution_count": 184,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "max_sequence_length = 40#200\n",
    "\n",
    "def is_valid_tokens(sentence, vocab):\n",
    "    for token in list(set(sentence)):\n",
    "        if token not in vocab:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def is_valid_length(sentence, max_sequence_length):\n",
    "    return len(list(sentence)) < (max_sequence_length - 1) # need to re-add the end token so leaving 1 space\n",
    "\n",
    "valid_sentence_indicies = []\n",
    "for index in range(len(kannada_sentences)):\n",
    "    kannada_sentence, english_sentence = kannada_sentences[index], english_sentences[index]\n",
    "    if is_valid_length(kannada_sentence, max_sequence_length) \\\n",
    "      and is_valid_length(english_sentence, max_sequence_length) \\\n",
    "      and is_valid_tokens(kannada_sentence, kannada_vocabulary):\n",
    "        valid_sentence_indicies.append(index)\n",
    "\n",
    "print(f\"Number of sentences: {len(kannada_sentences)}\")\n",
    "print(f\"Number of valid sentences: {len(valid_sentence_indicies)}\")"
   ],
   "metadata": {
    "id": "iVx4oG8OFaJo",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ed8aabc7-f7c9-4d05-ba08-222429132f11",
    "ExecuteTime": {
     "end_time": "2024-08-13T22:54:08.894474Z",
     "start_time": "2024-08-13T22:54:08.886299Z"
    }
   },
   "execution_count": 185,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "kannada_sentences = [kannada_sentences[i] for i in valid_sentence_indicies]\n",
    "english_sentences = [english_sentences[i] for i in valid_sentence_indicies]"
   ],
   "metadata": {
    "id": "fBzpWRdqFeaQ",
    "ExecuteTime": {
     "end_time": "2024-08-13T22:54:08.927161Z",
     "start_time": "2024-08-13T22:54:08.924605Z"
    }
   },
   "execution_count": 186,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "kannada_sentences[:3]"
   ],
   "metadata": {
    "id": "hiSCU6iuFgWu",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "81f3e9c5-16af-4fd4-c934-81d966495a1c",
    "ExecuteTime": {
     "end_time": "2024-08-13T22:54:08.952992Z",
     "start_time": "2024-08-13T22:54:08.948882Z"
    }
   },
   "execution_count": 187,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "\n",
    "    def __init__(self, english_sentences, kannada_sentences):\n",
    "        self.english_sentences = english_sentences\n",
    "        self.kannada_sentences = kannada_sentences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.english_sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.english_sentences[idx], self.kannada_sentences[idx]"
   ],
   "metadata": {
    "id": "cP5OA__hHoid",
    "ExecuteTime": {
     "end_time": "2024-08-13T22:54:08.994277Z",
     "start_time": "2024-08-13T22:54:08.990794Z"
    }
   },
   "execution_count": 188,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataset = TextDataset(english_sentences, kannada_sentences)"
   ],
   "metadata": {
    "id": "chdO2iYhIn_K",
    "ExecuteTime": {
     "end_time": "2024-08-13T22:54:09.015496Z",
     "start_time": "2024-08-13T22:54:09.013427Z"
    }
   },
   "execution_count": 189,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "len(dataset)"
   ],
   "metadata": {
    "id": "QfaWiz_8Iofr",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "cf854361-a810-4c00-92fa-1966f7b58259",
    "ExecuteTime": {
     "end_time": "2024-08-13T22:54:09.063832Z",
     "start_time": "2024-08-13T22:54:09.061263Z"
    }
   },
   "execution_count": 190,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "dataset[1]"
   ],
   "metadata": {
    "id": "dymqlSxZIqeg",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "9c50cdcd-a5eb-4961-af74-7d3baf51d341",
    "ExecuteTime": {
     "end_time": "2024-08-13T22:54:09.096119Z",
     "start_time": "2024-08-13T22:54:09.093084Z"
    }
   },
   "execution_count": 191,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "batch_size = 3 \n",
    "train_loader = DataLoader(dataset, batch_size)\n",
    "iterator = iter(train_loader)"
   ],
   "metadata": {
    "id": "7xQZ-bUsIukw",
    "ExecuteTime": {
     "end_time": "2024-08-13T22:54:09.141461Z",
     "start_time": "2024-08-13T22:54:09.138347Z"
    }
   },
   "execution_count": 192,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "for batch_num, batch in enumerate(iterator):\n",
    "    print(batch)\n",
    "    if batch_num > 3:\n",
    "        break"
   ],
   "metadata": {
    "id": "EMMZECktIyip",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "325eca43-8d2d-44ec-8793-3748f921ba75",
    "ExecuteTime": {
     "end_time": "2024-08-13T22:54:09.168897Z",
     "start_time": "2024-08-13T22:54:09.164716Z"
    }
   },
   "execution_count": 193,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "def tokenize(sentence, language_to_index, start_token=True, end_token=True):\n",
    "    sentence_word_indicies = [language_to_index[token] for token in list(sentence)]\n",
    "    if start_token:\n",
    "        sentence_word_indicies.insert(0, language_to_index[START_TOKEN])\n",
    "    if end_token:\n",
    "        sentence_word_indicies.append(language_to_index[END_TOKEN])\n",
    "    for _ in range(len(sentence_word_indicies), max_sequence_length):\n",
    "        sentence_word_indicies.append(language_to_index[PADDING_TOKEN])\n",
    "    return torch.tensor(sentence_word_indicies)"
   ],
   "metadata": {
    "id": "wf9LqFyjJFGs",
    "ExecuteTime": {
     "end_time": "2024-08-13T22:54:09.205615Z",
     "start_time": "2024-08-13T22:54:09.202871Z"
    }
   },
   "execution_count": 194,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "batch"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iqKgDTgHpZx7",
    "outputId": "88972da2-cfbc-4b50-b6c7-8eda5decbc9b",
    "ExecuteTime": {
     "end_time": "2024-08-13T22:54:09.226446Z",
     "start_time": "2024-08-13T22:54:09.224028Z"
    }
   },
   "execution_count": 195,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "batch[1]",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mf3oWss4po_n",
    "outputId": "91aa4f14-5d7f-4005-ba6c-310adad7cdfc",
    "ExecuteTime": {
     "end_time": "2024-08-13T22:54:09.248611Z",
     "start_time": "2024-08-13T22:54:09.245922Z"
    }
   },
   "execution_count": 196,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "eng_tokenized, kn_tokenized = [], []\n",
    "for sentence_num in range(batch_size):\n",
    "    eng_sentence, kn_sentence = batch[0][sentence_num], batch[1][sentence_num]\n",
    "    eng_tokenized.append( tokenize(eng_sentence, english_to_index, start_token=False, end_token=False) )\n",
    "    kn_tokenized.append( tokenize(kn_sentence, kannada_to_index, start_token=True, end_token=True) )\n",
    "eng_tokenized = torch.stack(eng_tokenized)\n",
    "kn_tokenized = torch.stack(kn_tokenized)"
   ],
   "metadata": {
    "id": "6Ng2eqyKJH9-",
    "ExecuteTime": {
     "end_time": "2024-08-13T22:54:09.281333Z",
     "start_time": "2024-08-13T22:54:09.278333Z"
    }
   },
   "execution_count": 197,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "eng_tokenized"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vYIMgY4eqYtF",
    "outputId": "9afd4417-8c39-4d6e-face-5fad6b5ccb24",
    "ExecuteTime": {
     "end_time": "2024-08-13T22:54:09.304106Z",
     "start_time": "2024-08-13T22:54:09.300386Z"
    }
   },
   "execution_count": 198,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "NEG_INFTY = -1e9\n",
    "\n",
    "def create_masks(eng_batch, kn_batch):\n",
    "    num_sentences = len(eng_batch)\n",
    "    look_ahead_mask = torch.full([max_sequence_length, max_sequence_length] , True)\n",
    "    look_ahead_mask = torch.triu(look_ahead_mask, diagonal=1)\n",
    "    encoder_padding_mask = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
    "    decoder_padding_mask_self_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
    "    decoder_padding_mask_cross_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
    "\n",
    "    for idx in range(num_sentences):\n",
    "      eng_sentence_length, kn_sentence_length = len(eng_batch[idx]), len(kn_batch[idx])\n",
    "      eng_chars_to_padding_mask = np.arange(eng_sentence_length + 1, max_sequence_length)\n",
    "      kn_chars_to_padding_mask = np.arange(kn_sentence_length + 1, max_sequence_length)\n",
    "      encoder_padding_mask[idx, :, eng_chars_to_padding_mask] = True\n",
    "      encoder_padding_mask[idx, eng_chars_to_padding_mask, :] = True\n",
    "      decoder_padding_mask_self_attention[idx, :, kn_chars_to_padding_mask] = True\n",
    "      decoder_padding_mask_self_attention[idx, kn_chars_to_padding_mask, :] = True\n",
    "      decoder_padding_mask_cross_attention[idx, :, eng_chars_to_padding_mask] = True\n",
    "      decoder_padding_mask_cross_attention[idx, kn_chars_to_padding_mask, :] = True\n",
    "\n",
    "    encoder_self_attention_mask = torch.where(encoder_padding_mask, NEG_INFTY, 0)\n",
    "    decoder_self_attention_mask =  torch.where(look_ahead_mask + decoder_padding_mask_self_attention, NEG_INFTY, 0)\n",
    "    decoder_cross_attention_mask = torch.where(decoder_padding_mask_cross_attention, NEG_INFTY, 0)\n",
    "    print(f\"encoder_self_attention_mask {encoder_self_attention_mask.size()}: {encoder_self_attention_mask[0, :10, :10]}\")\n",
    "    print(f\"decoder_self_attention_mask {decoder_self_attention_mask.size()}: {decoder_self_attention_mask[0, :10, :10]}\")\n",
    "    print(f\"decoder_cross_attention_mask {decoder_cross_attention_mask.size()}: {decoder_cross_attention_mask[0, :10, :10]}\")\n",
    "    return encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask"
   ],
   "metadata": {
    "id": "Mu581-voJPvp",
    "ExecuteTime": {
     "end_time": "2024-08-13T22:54:09.331262Z",
     "start_time": "2024-08-13T22:54:09.326325Z"
    }
   },
   "execution_count": 199,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "create_masks(batch[0], batch[1])"
   ],
   "metadata": {
    "id": "qY1xAivZJWOx",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "893b5441-d1db-44c0-aff3-8093a9756154",
    "ExecuteTime": {
     "end_time": "2024-08-13T22:54:09.359212Z",
     "start_time": "2024-08-13T22:54:09.349476Z"
    }
   },
   "execution_count": 200,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class SentenceEmbedding(nn.Module):\n",
    "    \"For a given sentence, create an embedding\"\n",
    "    def __init__(self, max_sequence_length, d_model, language_to_index, START_TOKEN, END_TOKEN, PADDING_TOKEN):\n",
    "        super().__init__()\n",
    "        self.vocab_size = len(language_to_index)\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.embedding = nn.Embedding(self.vocab_size, d_model)\n",
    "        self.language_to_index = language_to_index\n",
    "        self.position_encoder = PositionalEncoding(d_model, max_sequence_length)\n",
    "        self.dropout = nn.Dropout(p=0.1)\n",
    "        self.START_TOKEN = START_TOKEN\n",
    "        self.END_TOKEN = END_TOKEN\n",
    "        self.PADDING_TOKEN = PADDING_TOKEN\n",
    "    \n",
    "    def batch_tokenize(self, batch, start_token=True, end_token=True):\n",
    "\n",
    "        def tokenize(sentence, start_token=True, end_token=True):\n",
    "            sentence_word_indicies = [self.language_to_index[token] for token in list(sentence)]\n",
    "            if start_token:\n",
    "                sentence_word_indicies.insert(0, self.language_to_index[self.START_TOKEN])\n",
    "            if end_token:\n",
    "                sentence_word_indicies.append(self.language_to_index[self.END_TOKEN])\n",
    "            for _ in range(len(sentence_word_indicies), self.max_sequence_length):\n",
    "                sentence_word_indicies.append(self.language_to_index[self.PADDING_TOKEN])\n",
    "            return torch.tensor(sentence_word_indicies)\n",
    "\n",
    "        tokenized = []\n",
    "        for sentence_num in range(len(batch)):\n",
    "           tokenized.append( tokenize(batch[sentence_num], start_token, end_token) )\n",
    "        tokenized = torch.stack(tokenized)\n",
    "        return tokenized.to(get_device())\n",
    "    \n",
    "    def forward(self, x, end_token=True): # sentence\n",
    "        x = self.batch_tokenize(x ,end_token)\n",
    "        x = self.embedding(x)\n",
    "        pos = self.position_encoder().to(get_device())\n",
    "        x = self.dropout(x + pos)\n",
    "        return x\n"
   ],
   "metadata": {
    "id": "L770BHODEpvw",
    "ExecuteTime": {
     "end_time": "2024-08-13T22:54:09.393839Z",
     "start_time": "2024-08-13T22:54:09.387823Z"
    }
   },
   "execution_count": 201,
   "outputs": []
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-13T22:54:09.410918Z",
     "start_time": "2024-08-13T22:54:09.409275Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "execution_count": 201,
   "outputs": []
  }
 ]
}
