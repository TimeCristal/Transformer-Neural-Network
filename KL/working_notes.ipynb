{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def set_seed(seed):\n",
    "    \"\"\"\n",
    "    Set seeds for reproducibility.\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "set_seed(42)    "
   ],
   "id": "12ba30f377fcfe15",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from kl.homoscedastic_transformer import HomoscedasticTransformer as HomoTrans\n",
    "from kl.utils import load_fx\n",
    "\n",
    "\n",
    "window_size = 10\n",
    "pair = 'EURUSD'\n",
    "X, y, returns = load_fx(data_start=0, data_end=5000, window_size=window_size, shift=1, pair=pair)\n",
    "X_new, y_new, returns_new = load_fx(data_start=0, data_end=6000, window_size=window_size, shift=1, pair=pair)\n",
    "\n",
    "input_size = X.shape[1]\n",
    "hidden_size = 500\n",
    "latent_size = 10  # Latent space dimension\n",
    "\n",
    "ht = HomoTrans(input_size=input_size, hidden_size=hidden_size, latent_size=latent_size, verbose=True)\n",
    "\n",
    "X_Tensor = torch.tensor(X, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.long)\n",
    "X_Tensor_new = torch.tensor(X_new, dtype=torch.float32)\n",
    "y_tensor_new = torch.tensor(y_new, dtype=torch.long)\n",
    "\n",
    "# Fit the model and transform data\n",
    "ht.fit(X_Tensor, epochs=3000)# at 3000 epoch reach steady loss ~ 1.0"
   ],
   "id": "c6952ba71f31a17d",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_Homo = ht.transform(X_Tensor)\n",
    "X_Homo1 = ht.transform(X_Tensor)\n",
    "X_Homo_new = ht.transform(X_Tensor_new)\n",
    "plt.plot(X_Homo[0:50,0])\n",
    "plt.plot(X_Homo_new[0:50,0])\n",
    "plt.title('Homoscedastic transformation')\n",
    "plt.show()"
   ],
   "id": "7e4fcc455fc35d3a",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(f'Std : {np.std(X_Homo)}, Std new : {np.std(X_Homo_new)}')",
   "id": "8cc586f8e35d4b2b",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.plot(X_Homo)\n",
    "plt.plot(X_Homo_new)\n",
    "plt.title('Homoscedastic transformation')\n",
    "plt.show()"
   ],
   "id": "c89931f1c464ffde",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "np.savetxt('X_Homo.csv', X_Homo, delimiter=',')\n",
    "np.savetxt('X_Homo_new.csv', X_Homo_new, delimiter=',')\n",
    "# np.savetxt('X.csv', X, delimiter=',')\n",
    "# np.savetxt('X_new.csv', X_new, delimiter=',')\n"
   ],
   "id": "928f14287d610634",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "np.savetxt(\"reconstructed_data_homo.csv\", X_Homo, delimiter=\",\")",
   "id": "10db5108a299f05d",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from statsmodels.stats.diagnostic import het_arch\n",
    "from termcolor import colored\n",
    "# Perform Engle's ARCH test for heteroscedasticity on the residuals\n",
    "arch_test_resid = het_arch(X_Homo_new[:,0])\n",
    "#arch_test_resid = het_arch(X[:,0])\n",
    "\n",
    "# Extract the test statistic and p-value\n",
    "arch_stat_resid = arch_test_resid[0]\n",
    "arch_p_value_resid = arch_test_resid[1]\n",
    "\n",
    "print(f'ARCH Test Statistic: {arch_stat_resid}')\n",
    "print(f'p-value: {arch_p_value_resid:.4f}')\n",
    "if arch_p_value_resid > 0.05:\n",
    "    print(colored(\"A p-value > 0.05 means that heteroscedasticity is no longer present in the residuals, indicating that VAE has successfully reduced it.\",'red'))\n",
    "else:\n",
    "    print(f\"VAE fail to reduce heteroscedasticity\")"
   ],
   "id": "ed6d3f9ae8426b9f",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from arch import arch_model\n",
    "\n",
    "# Rescale the data (multiply by 100)\n",
    "scaled_data = X_Homo_new[:,0] * 10\n",
    "\n",
    "# Fit the GARCH model with rescaled data\n",
    "garch_model = arch_model(scaled_data, vol='GARCH', p=1, q=1)\n",
    "garch_rescaled_fitted = garch_model.fit(disp=\"off\")\n",
    "\n",
    "# Summarize the model\n",
    "print(garch_rescaled_fitted.summary())\n",
    "\n",
    "\n",
    "# Forecasting future volatility with rescaled data\n",
    "forecast = garch_rescaled_fitted.forecast(horizon=5)\n",
    "forecast_variance_rescaled = forecast.variance[-1:] / 10  # Scale back\n",
    "print(forecast_variance_rescaled)"
   ],
   "id": "8ec82933edc5685c",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "# Plot the conditional volatility over time (variance over time)\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Plot the conditional volatility (square root of variance)\n",
    "conditional_volatility = garch_rescaled_fitted.conditional_volatility\n",
    "plt.plot(garch_rescaled_fitted.conditional_volatility, label='Conditional Volatility')\n",
    "plt.title('Conditional Volatility Over Time (GARCH Model)')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Conditional Volatility')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "876c1eb539e182b1",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import json\n",
    "def read_config(config_path):\n",
    "    with open(config_path, 'r') as f:\n",
    "        config_ = json.load(f)\n",
    "    return config_\n",
    "config = read_config(\"dichotomy_config.json\")\n",
    "latent_dim = config.get(\"latent_dim\", 2)"
   ],
   "id": "7c513646f3cbab03",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from kl.dichotomy_vae import DichotomyVAE, LossType\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from datetime import datetime\n",
    "\n",
    "# Example usage for fitting and transforming data\n",
    "input_dim = X.shape[1]\n",
    "vae_model = DichotomyVAE(input_dim=input_dim, output_dim=input_dim, latent_dim=latent_dim, num_classes=2, loss_type = LossType.Classifier, verbose=True)\n",
    "optimizer = optim.Adam(vae_model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.PolynomialLR(optimizer, total_iters=5000)\n",
    "\n",
    "\n",
    "X_Homo_Tensor = torch.tensor(X, dtype=torch.float)\n",
    "X_Homo_Tensor_new = torch.tensor(X_new, dtype=torch.float)\n",
    "\n",
    "# Create a DataLoader for batching\n",
    "batch_size = 64\n",
    "dataset = TensorDataset(X_Homo_Tensor, y_tensor)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ],
   "id": "b9aa9db9687d9887",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "start_time = datetime.now()\n",
    "# Fit and transform\n",
    "vae_model.fit(dataloader, optimizer, scheduler, num_epochs=5000, beta=1, lambda_class=1)\n",
    "\n",
    "# Strange order of transform\n",
    "x_reconstructed, latent_representation, predicted_class = vae_model.transform(X_Homo_Tensor) \n",
    "x_reconstructed1, latent_representation1, predicted_class1 = vae_model.transform(X_Homo_Tensor) \n",
    "x_reconstructed_new, latent_representation_new, predicted_class_new = vae_model.transform(X_Homo_Tensor_new) \n",
    "\n",
    "end_time = datetime.now()\n",
    "# Execution time\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time}\")"
   ],
   "id": "6b6092af88af9f8d",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x_reconstructed_np = x_reconstructed.cpu().detach().numpy()\n",
    "x_reconstructed_np_new = x_reconstructed_new.detach().cpu().numpy()\n",
    "np.savetxt(\"x_reconstructed_np.csv\", x_reconstructed_np, delimiter=\",\")\n",
    "np.savetxt(\"x_reconstructed_np_new.csv\", x_reconstructed_np_new, delimiter=\",\")\n",
    "\n",
    "latent_representation_np = latent_representation.detach().cpu().numpy()\n",
    "latent_representation_np_new = latent_representation_new.detach().cpu().numpy()\n",
    "np.savetxt(\"latent_representation_np.csv\", latent_representation_np, delimiter=\",\")\n",
    "np.savetxt(\"latent_representation_np_new.csv\", latent_representation_np_new, delimiter=\",\")\n",
    "\n",
    "predicted_class_np = predicted_class.cpu().detach().numpy()\n",
    "np.savetxt(\"predicted_class_np.csv\", predicted_class_np, delimiter=\",\")\n",
    "\n",
    "np.savetxt(\"real_class_np.csv\", y, delimiter=\",\")\n",
    "np.savetxt(\"real_class_np_new.csv\", y_new, delimiter=\",\")"
   ],
   "id": "8c8953f0944d1098",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "predicted_class_np_new = predicted_class_new.cpu().detach().numpy()",
   "id": "ca098844533b4025",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(f'Class Mean: {np.mean(predicted_class_np)}')",
   "id": "d7875b972c336686",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "acc_trn = accuracy_score(y, predicted_class_np)\n",
    "print(f\"Train Accuracy: {acc_trn}\")\n",
    "\n",
    "acc_tst = accuracy_score(y_new[5000:5050,], predicted_class_np_new[5000:5050,])\n",
    "print(f\"Train Accuracy: {acc_tst}\")"
   ],
   "id": "9f96057d51d60161",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# visualize the embedding\n",
    "from sklearn. preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "latent_representation_np = scaler.fit_transform(latent_representation_np)\n",
    "if np.shape(latent_representation)[1] == 3:\n",
    "    fig, _ = plt.subplots(1, 1, figsize=(6, 6))\n",
    "    ax = plt.axes(projection =\"3d\")\n",
    "    ax.scatter(latent_representation_np[:, 0], latent_representation_np[:, 1], latent_representation_np[:, 2], cmap=\"autumn\", c=y, s=20)\n",
    "elif np.shape(latent_representation)[1] == 2:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "    ax.scatter(latent_representation_np[:, 0], latent_representation_np[:, 1], cmap=\"autumn\", c=y, s=20)   \n",
    "else:\n",
    "    print(\"Can Not Plot Latent Representation. Dimensions Mismatch\")"
   ],
   "id": "51e1563b20abcfdb",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "_, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "color_list = ['r', 'g', 'b', 'c', 'y', 'k', 'm', 'w']\n",
    "for i in range(np.shape(latent_representation)[1]):\n",
    "    ax.hist(latent_representation_np[:, i], bins=50, color=color_list[i])"
   ],
   "id": "b576f835a1000f1e",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "_, ax = plt.subplots(1, 1, figsize=(6, 6))\n",
    "ax.set_title('Reconstructed')\n",
    "for i in range(np.shape(x_reconstructed_np)[1]):\n",
    "    ax.hist(x_reconstructed_np[:, i], bins=50, color=color_list[i])"
   ],
   "id": "e9943fea5769b581",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "df = pd.DataFrame(x_reconstructed_np)\n",
    "# df = pd.DataFrame(latent_representation_np)\n",
    "corr = df.corr()\n",
    "sns.heatmap(corr, annot = True)\n",
    "plt.show()"
   ],
   "id": "31d74ee49051dc7b",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "mutual_info_classif(latent_representation_np, y)\n",
    "# mutual_info_classif(x_reconstructed_np, y)\n"
   ],
   "id": "e5aff93137f69534",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=np.shape(latent_representation_np)[1])\n",
    "pca.fit(latent_representation_np)\n",
    "# pca = PCA(n_components=8, )\n",
    "# pca.fit(x_reconstructed_np)\n",
    "\n",
    "print(pca.explained_variance_ratio_)"
   ],
   "id": "bf4c4d103bfa4775",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=0)\n",
    "x_train = latent_representation_np[0:4500,:]\n",
    "y_train = y[0:4500]\n",
    "x_test = latent_representation_np[4500:,:]\n",
    "y_test = y[4500:]\n",
    "rf.fit(x_train, y_train)\n",
    "y_pred = rf.predict(x_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy Random Forest: {acc}\")"
   ],
   "id": "48ab2280f408118d",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "clf = AdaBoostClassifier(n_estimators=100, algorithm=\"SAMME\", random_state=0)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy AdaBoost: {acc}\")"
   ],
   "id": "3cfee493a478e9a0",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "\n",
    "clf = BaggingClassifier(estimator=SVC(), n_estimators=100, random_state=0)\n",
    "clf.fit(x_train, y_train) \n",
    "y_pred = clf.predict(x_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy BaggingClassifier: {acc}\")"
   ],
   "id": "e0697095a5014f92",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "clf1 = LogisticRegression(random_state=1)\n",
    "clf2 = RandomForestClassifier(n_estimators=100, random_state=1)\n",
    "clf3 = GaussianNB()\n",
    "eclf1 = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], voting='hard')\n",
    "eclf1.fit(x_train, y_train)\n",
    "y_pred = eclf1.predict(x_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy Voting: {acc}\")"
   ],
   "id": "f4b703696102012",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "clf = HistGradientBoostingClassifier()\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy HistGradientBoostingClassifier: {acc}\")"
   ],
   "id": "cd5448f896f074f3",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy GradientBoostingClassifier: {acc}\")"
   ],
   "id": "9963b6e9b105aef3",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x_train = x_reconstructed_np[0:4500,:]\n",
    "x_test = x_reconstructed_np[4500:,:]\n",
    "rf.fit(x_train, y_train)\n",
    "y_pred = rf.predict(x_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Reconstructed Test Accuracy Random Forest: {acc}\")"
   ],
   "id": "d1f9a7a8a9c3036b",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Random Forest \n",
    "Latent 4 - 72%\n",
    "Latent 3 - 86%\n",
    "Latent 2 - 92%\n",
    "Reconstructed 2 - 92%"
   ],
   "id": "4d7e93271722e0a5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "clf = HistGradientBoostingClassifier()\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Reconstructed Test Accuracy HistGradientBoostingClassifier: {acc}\")"
   ],
   "id": "dfe882b2da70ae83",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Reconstructed Test Accuracy GradientBoostingClassifier: {acc}\")"
   ],
   "id": "4d3918cd62ea7541",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "eclf1.fit(x_train, y_train)\n",
    "y_pred = eclf1.predict(x_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Reconstructed Test Accuracy Voting: {acc}\")"
   ],
   "id": "b14bab5b864d1b6b",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "clf = ExtraTreesClassifier(n_estimators=100, random_state=0)\n",
    "clf.fit(x_train, y_train)\n",
    "y_pred = clf.predict(x_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Reconstructed Test Accuracy ExtraTreesClassifier: {acc}\")"
   ],
   "id": "3aefb0e21e440140",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# x_reconstructed_new, latent_representation_new, predicted_class_new = vae_model.transform(X_Homo_Tensor_new) \n",
    "clf = ExtraTreesClassifier(n_estimators=100, random_state=0)\n",
    "clf.fit(latent_representation_np, y)\n",
    "y_pred = clf.predict(latent_representation_np_new[5000:5050,:])\n",
    "acc = accuracy_score(y_new[5000:5050,], y_pred)\n",
    "print(f\"Reconstructed Test Accuracy ExtraTreesClassifier: {acc}\")"
   ],
   "id": "97ed5125d2b0b729",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "x_reconstructed_np1 = x_reconstructed1.cpu().detach().numpy()\n",
    "clf = ExtraTreesClassifier(n_estimators=100, random_state=0)\n",
    "clf.fit(x_reconstructed_np_new[0:4990,:], y)\n",
    "y_pred = clf.predict(x_reconstructed_np_new)\n",
    "acc = accuracy_score(y_new[5000:], y_pred[5000:])\n",
    "print(f\"Reconstructed Test Accuracy ExtraTreesClassifier: {acc}\")"
   ],
   "id": "286233a229a41d4b",
   "execution_count": null,
   "outputs": []
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.plot(y_pred[4990:5020,])\n",
    "plt.plot(y_new[4990:5020,])"
   ],
   "id": "ceac0bddf30d595f",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
