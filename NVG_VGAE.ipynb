{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "###\t1.\tInstall Necessary Libraries:\n",
    "Ensure that you have the necessary libraries installed. You can install PyTorch-Geometric and its dependencies using pip if you haven’t already:"
   ],
   "id": "ef426fa6397a4116"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T18:25:23.260253Z",
     "start_time": "2024-08-23T18:25:23.255483Z"
    }
   },
   "cell_type": "code",
   "source": "#!pip install torch torch-geometric",
   "id": "initial_id",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### 1.a. Handle graph saving and loading ",
   "id": "565043f22b3352c9"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T18:25:23.302456Z",
     "start_time": "2024-08-23T18:25:23.298727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pickle\n",
    "\n",
    "def save_graph(graph, filename):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(graph, f)\n",
    "\n",
    "def load_graph(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "# Filepath where the graph will be saved\n",
    "graph_filename = 'nvg_graph.pkl'    "
   ],
   "id": "81bb5cd4df3df3f3",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T18:25:23.310507Z",
     "start_time": "2024-08-23T18:25:23.304370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import networkx as nx\n",
    "def create_nvg(prices):\n",
    "    N = len(prices)\n",
    "    G = nx.Graph()\n",
    "    \n",
    "    for i in range(N):\n",
    "        G.add_node(i, feature=prices[i])\n",
    "        for j in range(i + 1, N):\n",
    "            visibility = True\n",
    "            for k in range(i + 1, j):\n",
    "                # Linear interpolation between points i and j at point k\n",
    "                expected_value_at_k = prices[i] + (prices[j] - prices[i]) * (k - i) / (j - i)\n",
    "                \n",
    "                # Check if point k obstructs the visibility\n",
    "                if prices[k] >= expected_value_at_k:\n",
    "                    visibility = False\n",
    "                    break\n",
    "            if visibility:\n",
    "                G.add_edge(i, j)\n",
    "                \n",
    "    return G"
   ],
   "id": "6b956cfafbd98947",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T18:25:23.337434Z",
     "start_time": "2024-08-23T18:25:23.315544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "# Check if the graph file exists\n",
    "if os.path.exists(graph_filename):\n",
    "    print(\"Loading graph from disk...\")\n",
    "    g = load_graph(graph_filename)\n",
    "else:\n",
    "    print(\"Creating and saving graph...\")\n",
    "    df = pd.read_csv(\"dataset/EURUSD_Daily_200005300000_202405300000.csv\", delimiter=\"\\t\")\n",
    "    # Extract the closing prices from the DataFrame\n",
    "    closing = df[\"<CLOSE>\"]\n",
    "    g = create_nvg(closing)\n",
    "    save_graph(g, graph_filename)\n",
    "    print(\"Saving graph to disk...\")"
   ],
   "id": "6fa0a932cbacf283",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading graph from disk...\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T18:25:24.380768Z",
     "start_time": "2024-08-23T18:25:23.338914Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch_geometric.utils import from_networkx\n",
    "import numpy as np\n",
    "import torch\n",
    "# Convert NetworkX graph to PyTorch Geometric format\n",
    "dataset = from_networkx(g)\n",
    "# Extract the node features (closing prices)\n",
    "node_features = np.array([g.nodes[n]['feature'] for n in g.nodes])\n",
    "\n",
    "# Assign features to the graph\n",
    "dataset.x = torch.tensor(node_features, dtype=torch.float).view(-1, 1)"
   ],
   "id": "b5af258ab50405d2",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T18:25:24.384283Z",
     "start_time": "2024-08-23T18:25:24.381837Z"
    }
   },
   "cell_type": "code",
   "source": "print(dataset)",
   "id": "3baf0cbd5f745e72",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(edge_index=[2, 93590], feature=[6241], num_nodes=6241, x=[6241, 1])\n"
     ]
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "###\t2.\tLoad and Prepare the Dataset:\n",
    "We’ll use the Cora dataset, which is a standard citation network dataset. The nodes represent documents, and the edges represent citations between them."
   ],
   "id": "e17dde0561c63c5d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T18:25:24.470766Z",
     "start_time": "2024-08-23T18:25:24.385924Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch_geometric.transforms import RandomLinkSplit\n",
    "import torch\n",
    "\n",
    "# Split the edges into training, validation, and test sets\n",
    "transform = RandomLinkSplit(is_undirected=True, key=\"edge_label\", split_labels=True)\n",
    "\n",
    "train_data, val_data, test_data = transform(dataset)"
   ],
   "id": "a5f4bfab39622ded",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "###\t3.\tDefine the VGAE Model:\n",
    "We need to define the VGAE model, which consists of an encoder that maps the input features into a latent space. The encoder is typically implemented using Graph Convolutional Networks (GCNs)."
   ],
   "id": "e76734ca84783d48"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T18:25:24.480676Z",
     "start_time": "2024-08-23T18:25:24.471869Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch_geometric.nn import VGAE, GCNConv\n",
    "class GCNEncoder(torch.nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(GCNEncoder, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels, 2 * out_channels)\n",
    "        self.conv_mu = GCNConv(2 * out_channels, out_channels)\n",
    "        self.conv_logstd = GCNConv(2 * out_channels, out_channels)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        mu = self.conv_mu(x, edge_index)\n",
    "        logstd = self.conv_logstd(x, edge_index)\n",
    "        return mu, logstd\n",
    "\n",
    "# Initialize the VGAE model\n",
    "out_channels = 16\n",
    "model = VGAE(GCNEncoder(dataset.num_features, out_channels))"
   ],
   "id": "2c6bd8c2f741c16",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "###\t4.\tTraining the Model:\n",
    "The model is trained by optimizing a loss function that combines a reconstruction loss (which ensures the graph is reconstructed correctly) and a KL divergence loss (which regularizes the latent space)."
   ],
   "id": "2145d6d6aad9fda8"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T18:36:10.741732Z",
     "start_time": "2024-08-23T18:25:24.481733Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    z = model.encode(train_data.x, train_data.edge_index)\n",
    "    loss = model.recon_loss(z, train_data.edge_index)\n",
    "    loss = loss + (1 / train_data.num_nodes) * model.kl_loss()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "# Train the model for 5000 epochs\n",
    "for epoch in range(5000):\n",
    "    loss = train()\n",
    "    if epoch % 100 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}')"
   ],
   "id": "7fe6efb800a06eb4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Loss: 3.9626\n",
      "Epoch: 100, Loss: 1.1973\n",
      "Epoch: 200, Loss: 1.1792\n",
      "Epoch: 300, Loss: 1.1560\n",
      "Epoch: 400, Loss: 1.1579\n",
      "Epoch: 500, Loss: 1.1563\n",
      "Epoch: 600, Loss: 1.1563\n",
      "Epoch: 700, Loss: 1.1537\n",
      "Epoch: 800, Loss: 1.1548\n",
      "Epoch: 900, Loss: 1.1485\n",
      "Epoch: 1000, Loss: 1.1560\n",
      "Epoch: 1100, Loss: 1.1482\n",
      "Epoch: 1200, Loss: 1.1470\n",
      "Epoch: 1300, Loss: 1.1444\n",
      "Epoch: 1400, Loss: 1.1390\n",
      "Epoch: 1500, Loss: 1.1360\n",
      "Epoch: 1600, Loss: 1.1299\n",
      "Epoch: 1700, Loss: 1.1309\n",
      "Epoch: 1800, Loss: 1.1312\n",
      "Epoch: 1900, Loss: 1.1312\n",
      "Epoch: 2000, Loss: 1.1324\n",
      "Epoch: 2100, Loss: 1.1281\n",
      "Epoch: 2200, Loss: 1.1319\n",
      "Epoch: 2300, Loss: 1.1342\n",
      "Epoch: 2400, Loss: 1.1318\n",
      "Epoch: 2500, Loss: 1.1264\n",
      "Epoch: 2600, Loss: 1.1319\n",
      "Epoch: 2700, Loss: 1.1327\n",
      "Epoch: 2800, Loss: 1.1281\n",
      "Epoch: 2900, Loss: 1.1341\n",
      "Epoch: 3000, Loss: 1.1305\n",
      "Epoch: 3100, Loss: 1.1311\n",
      "Epoch: 3200, Loss: 1.1285\n",
      "Epoch: 3300, Loss: 1.1353\n",
      "Epoch: 3400, Loss: 1.1298\n",
      "Epoch: 3500, Loss: 1.1288\n",
      "Epoch: 3600, Loss: 1.1322\n",
      "Epoch: 3700, Loss: 1.1274\n",
      "Epoch: 3800, Loss: 1.1294\n",
      "Epoch: 3900, Loss: 1.1298\n",
      "Epoch: 4000, Loss: 1.1317\n",
      "Epoch: 4100, Loss: 1.1293\n",
      "Epoch: 4200, Loss: 1.1313\n",
      "Epoch: 4300, Loss: 1.1283\n",
      "Epoch: 4400, Loss: 1.1338\n",
      "Epoch: 4500, Loss: 1.1301\n",
      "Epoch: 4600, Loss: 1.1297\n",
      "Epoch: 4700, Loss: 1.1270\n",
      "Epoch: 4800, Loss: 1.1296\n",
      "Epoch: 4900, Loss: 1.1330\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "###\t5.\tEvaluate the Model:\n",
    "After training, we can evaluate the model’s performance on the test set. The evaluation typically involves predicting the probability of edges (links) between nodes and comparing them to the true test edges."
   ],
   "id": "8640e14e743f1b75"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T18:36:10.810072Z",
     "start_time": "2024-08-23T18:36:10.744611Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Test the model\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score\n",
    "# Test the model\n",
    "def test(data):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        z = model.encode(data.x, data.edge_index)\n",
    "        pos_pred = model.decode(z, data.pos_edge_label_index).cpu().numpy()\n",
    "        neg_pred = model.decode(z, data.neg_edge_label_index).cpu().numpy()\n",
    "\n",
    "        y_pred = torch.cat([torch.tensor(pos_pred), torch.tensor(neg_pred)])\n",
    "        y_true = torch.cat([torch.ones(pos_pred.shape[0]), torch.zeros(neg_pred.shape[0])])\n",
    "\n",
    "        roc_auc = roc_auc_score(y_true, y_pred)\n",
    "        ap_score = average_precision_score(y_true, y_pred)\n",
    "\n",
    "        return roc_auc, ap_score\n",
    "\n",
    "roc_auc, ap_score = test(test_data)\n",
    "print(f'Test -> ROC AUC Score: {roc_auc:.4f}, Average Precision Score: {ap_score:.4f}')"
   ],
   "id": "16f0ff13b208eff2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test -> ROC AUC Score: 0.8149, Average Precision Score: 0.8267\n"
     ]
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T18:36:10.896489Z",
     "start_time": "2024-08-23T18:36:10.812069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "roc_auc, ap_score = test(train_data)\n",
    "print(f'Train -> ROC AUC Score: {roc_auc:.4f}, Average Precision Score: {ap_score:.4f}')"
   ],
   "id": "52f03a0c4ba678b0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train -> ROC AUC Score: 0.8316, Average Precision Score: 0.8395\n"
     ]
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-23T18:36:10.901499Z",
     "start_time": "2024-08-23T18:36:10.898731Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "9f785ae8387bfde8",
   "outputs": [],
   "execution_count": 44
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
